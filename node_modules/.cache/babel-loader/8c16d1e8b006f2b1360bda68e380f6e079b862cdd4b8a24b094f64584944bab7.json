{"ast":null,"code":"\"use strict\";\n\nvar __classPrivateFieldGet = this && this.__classPrivateFieldGet || function (receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar __classPrivateFieldSet = this && this.__classPrivateFieldSet || function (receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;\n};\nvar _Iter_peek;\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.TokenData = void 0;\nexports.parse = parse;\nexports.compile = compile;\nexports.match = match;\nconst DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = value => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\nconst DEBUG_URL = \"https://git.new/pathToRegexpError\";\nconst SIMPLE_TOKENS = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\"\n};\n/**\n * Escape a regular expression string.\n */\nfunction escape(str) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n/**\n * Get the flags for a regexp from the options.\n */\nfunction toFlags(options) {\n  return options.sensitive ? \"s\" : \"is\";\n}\n/**\n * Tokenize input string.\n */\nfunction* lexer(str) {\n  const chars = [...str];\n  let i = 0;\n  function name() {\n    let value = \"\";\n    if (ID_START.test(chars[++i])) {\n      value += chars[i];\n      while (ID_CONTINUE.test(chars[++i])) {\n        value += chars[i];\n      }\n    } else if (chars[i] === '\"') {\n      let pos = i;\n      while (i < chars.length) {\n        if (chars[++i] === '\"') {\n          i++;\n          pos = 0;\n          break;\n        }\n        if (chars[i] === \"\\\\\") {\n          value += chars[++i];\n        } else {\n          value += chars[i];\n        }\n      }\n      if (pos) {\n        throw new TypeError(`Unterminated quote at ${pos}: ${DEBUG_URL}`);\n      }\n    }\n    if (!value) {\n      throw new TypeError(`Missing parameter name at ${i}: ${DEBUG_URL}`);\n    }\n    return value;\n  }\n  while (i < chars.length) {\n    const value = chars[i];\n    const type = SIMPLE_TOKENS[value];\n    if (type) {\n      yield {\n        type,\n        index: i++,\n        value\n      };\n    } else if (value === \"\\\\\") {\n      yield {\n        type: \"ESCAPED\",\n        index: i++,\n        value: chars[i++]\n      };\n    } else if (value === \":\") {\n      const value = name();\n      yield {\n        type: \"PARAM\",\n        index: i,\n        value\n      };\n    } else if (value === \"*\") {\n      const value = name();\n      yield {\n        type: \"WILDCARD\",\n        index: i,\n        value\n      };\n    } else {\n      yield {\n        type: \"CHAR\",\n        index: i,\n        value: chars[i++]\n      };\n    }\n  }\n  return {\n    type: \"END\",\n    index: i,\n    value: \"\"\n  };\n}\nclass Iter {\n  constructor(tokens) {\n    this.tokens = tokens;\n    _Iter_peek.set(this, void 0);\n  }\n  peek() {\n    if (!__classPrivateFieldGet(this, _Iter_peek, \"f\")) {\n      const next = this.tokens.next();\n      __classPrivateFieldSet(this, _Iter_peek, next.value, \"f\");\n    }\n    return __classPrivateFieldGet(this, _Iter_peek, \"f\");\n  }\n  tryConsume(type) {\n    const token = this.peek();\n    if (token.type !== type) return;\n    __classPrivateFieldSet(this, _Iter_peek, undefined, \"f\"); // Reset after consumed.\n    return token.value;\n  }\n  consume(type) {\n    const value = this.tryConsume(type);\n    if (value !== undefined) return value;\n    const {\n      type: nextType,\n      index\n    } = this.peek();\n    throw new TypeError(`Unexpected ${nextType} at ${index}, expected ${type}: ${DEBUG_URL}`);\n  }\n  text() {\n    let result = \"\";\n    let value;\n    while (value = this.tryConsume(\"CHAR\") || this.tryConsume(\"ESCAPED\")) {\n      result += value;\n    }\n    return result;\n  }\n}\n_Iter_peek = new WeakMap();\n/**\n * Tokenized path instance.\n */\nclass TokenData {\n  constructor(tokens) {\n    this.tokens = tokens;\n  }\n}\nexports.TokenData = TokenData;\n/**\n * Parse a string for the raw tokens.\n */\nfunction parse(str, options = {}) {\n  const {\n    encodePath = NOOP_VALUE\n  } = options;\n  const it = new Iter(lexer(str));\n  function consume(endType) {\n    const tokens = [];\n    while (true) {\n      const path = it.text();\n      if (path) tokens.push({\n        type: \"text\",\n        value: encodePath(path)\n      });\n      const param = it.tryConsume(\"PARAM\");\n      if (param) {\n        tokens.push({\n          type: \"param\",\n          name: param\n        });\n        continue;\n      }\n      const wildcard = it.tryConsume(\"WILDCARD\");\n      if (wildcard) {\n        tokens.push({\n          type: \"wildcard\",\n          name: wildcard\n        });\n        continue;\n      }\n      const open = it.tryConsume(\"{\");\n      if (open) {\n        tokens.push({\n          type: \"group\",\n          tokens: consume(\"}\")\n        });\n        continue;\n      }\n      it.consume(endType);\n      return tokens;\n    }\n  }\n  const tokens = consume(\"END\");\n  return new TokenData(tokens);\n}\n/**\n * Transform tokens into a path building function.\n */\nfunction $compile(data, options) {\n  const {\n    encode = encodeURIComponent,\n    delimiter = DEFAULT_DELIMITER\n  } = options;\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n  return function path(data = {}) {\n    const [path, ...missing] = fn(data);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\n/**\n * Compile a string to a template function for the path.\n */\nfunction compile(path, options = {}) {\n  return $compile(path instanceof TokenData ? path : parse(path, options), options);\n}\nfunction tokensToFunction(tokens, delimiter, encode) {\n  const encoders = tokens.map(token => tokenToFunction(token, delimiter, encode));\n  return data => {\n    const result = [\"\"];\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n    return result;\n  };\n}\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(token, delimiter, encode) {\n  if (token.type === \"text\") return () => [token.value];\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n    return data => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n  const encodeValue = encode || NOOP_VALUE;\n  if (token.type === \"wildcard\" && encode !== false) {\n    return data => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n      return [value.map((value, index) => {\n        if (typeof value !== \"string\") {\n          throw new TypeError(`Expected \"${token.name}/${index}\" to be a string`);\n        }\n        return encodeValue(value);\n      }).join(delimiter)];\n    };\n  }\n  return data => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n    return [encodeValue(value)];\n  };\n}\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nfunction $match(data, options = {}) {\n  const {\n    decode = decodeURIComponent,\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    trailing = true\n  } = options;\n  const flags = toFlags(options);\n  const sources = [];\n  const keys = [];\n  for (const {\n    tokens\n  } of data) {\n    for (const seq of flatten(tokens, 0, [])) {\n      const regexp = sequenceToRegExp(seq, delimiter, keys);\n      sources.push(regexp);\n    }\n  }\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n  const re = new RegExp(pattern, flags);\n  const decoders = keys.map(key => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return value => value.split(delimiter).map(decode);\n  });\n  return Object.assign(function match(input) {\n    const m = re.exec(input);\n    if (!m) return false;\n    const {\n      0: path\n    } = m;\n    const params = Object.create(null);\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n    return {\n      path,\n      params\n    };\n  }, {\n    re\n  });\n}\nfunction match(path, options = {}) {\n  const paths = Array.isArray(path) ? path : [path];\n  const items = paths.map(path => path instanceof TokenData ? path : parse(path, options));\n  return $match(items, options);\n}\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(tokens, index, init) {\n  if (index === tokens.length) {\n    return yield init;\n  }\n  const token = tokens[index];\n  if (token.type === \"group\") {\n    const fork = init.slice();\n    for (const seq of flatten(token.tokens, 0, fork)) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n  yield* flatten(tokens, index + 1, init);\n}\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction sequenceToRegExp(tokens, delimiter, keys) {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n  for (let i = 0; i < tokens.length; i++) {\n    const token = tokens[i];\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack = token.value;\n      isSafeSegmentParam || (isSafeSegmentParam = token.value.includes(delimiter));\n      continue;\n    }\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new TypeError(`Missing text after \"${token.name}\": ${DEBUG_URL}`);\n      }\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `(.+)`;\n      }\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n  return result;\n}\nfunction negate(delimiter, backtrack) {\n  const values = [delimiter, backtrack].filter(Boolean);\n  const isSimple = values.every(value => value.length === 1);\n  if (isSimple) return `[^${escape(values.join(\"\"))}]`;\n  return `(?:(?!${values.map(escape).join(\"|\")}).)`;\n}","map":{"version":3,"names":["exports","parse","compile","match","DEFAULT_DELIMITER","NOOP_VALUE","value","ID_START","ID_CONTINUE","DEBUG_URL","SIMPLE_TOKENS","escape","str","replace","toFlags","options","sensitive","lexer","chars","i","name","test","pos","length","TypeError","type","index","Iter","constructor","tokens","_Iter_peek","set","peek","__classPrivateFieldGet","next","__classPrivateFieldSet","tryConsume","token","undefined","consume","nextType","text","result","TokenData","encodePath","it","endType","path","push","param","wildcard","open","$compile","data","encode","encodeURIComponent","delimiter","fn","tokensToFunction","missing","join","encoders","map","tokenToFunction","encoder","extras","encodeValue","Array","isArray","$match","decode","decodeURIComponent","end","trailing","flags","sources","keys","seq","flatten","regexp","sequenceToRegExp","pattern","re","RegExp","decoders","key","split","Object","assign","input","m","exec","params","create","decoder","paths","items","init","fork","slice","backtrack","isSafeSegmentParam","includes","negate","values","filter","Boolean","isSimple","every"],"sources":["/Users/phanluc/admin-web-fe/node_modules/@ant-design/pro-layout/node_modules/path-to-regexp/src/index.ts"],"sourcesContent":["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\nconst DEBUG_URL = \"https://git.new/pathToRegexpError\";\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * A function for encoding input strings.\n   */\n  encodePath?: Encode;\n}\n\nexport interface MatchOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n  /**\n   * Matches the path completely without trailing characters. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * Allows optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n  /**\n   * Match will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\nexport interface CompileOptions {\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"WILDCARD\"\n  | \"PARAM\"\n  | \"CHAR\"\n  | \"ESCAPED\"\n  | \"END\"\n  // Reserved for use or ambiguous due to past use.\n  | \"(\"\n  | \")\"\n  | \"[\"\n  | \"]\"\n  | \"+\"\n  | \"?\"\n  | \"!\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\",\n};\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction toFlags(options: { sensitive?: boolean }) {\n  return options.sensitive ? \"s\" : \"is\";\n}\n\n/**\n * Tokenize input string.\n */\nfunction* lexer(str: string): Generator<LexToken, LexToken> {\n  const chars = [...str];\n  let i = 0;\n\n  function name() {\n    let value = \"\";\n\n    if (ID_START.test(chars[++i])) {\n      value += chars[i];\n      while (ID_CONTINUE.test(chars[++i])) {\n        value += chars[i];\n      }\n    } else if (chars[i] === '\"') {\n      let pos = i;\n\n      while (i < chars.length) {\n        if (chars[++i] === '\"') {\n          i++;\n          pos = 0;\n          break;\n        }\n\n        if (chars[i] === \"\\\\\") {\n          value += chars[++i];\n        } else {\n          value += chars[i];\n        }\n      }\n\n      if (pos) {\n        throw new TypeError(`Unterminated quote at ${pos}: ${DEBUG_URL}`);\n      }\n    }\n\n    if (!value) {\n      throw new TypeError(`Missing parameter name at ${i}: ${DEBUG_URL}`);\n    }\n\n    return value;\n  }\n\n  while (i < chars.length) {\n    const value = chars[i];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      yield { type, index: i++, value };\n    } else if (value === \"\\\\\") {\n      yield { type: \"ESCAPED\", index: i++, value: chars[i++] };\n    } else if (value === \":\") {\n      const value = name();\n      yield { type: \"PARAM\", index: i, value };\n    } else if (value === \"*\") {\n      const value = name();\n      yield { type: \"WILDCARD\", index: i, value };\n    } else {\n      yield { type: \"CHAR\", index: i, value: chars[i++] };\n    }\n  }\n\n  return { type: \"END\", index: i, value: \"\" };\n}\n\nclass Iter {\n  #peek?: LexToken;\n\n  constructor(private tokens: Generator<LexToken, LexToken>) {}\n\n  peek(): LexToken {\n    if (!this.#peek) {\n      const next = this.tokens.next();\n      this.#peek = next.value;\n    }\n    return this.#peek;\n  }\n\n  tryConsume(type: TokenType): string | undefined {\n    const token = this.peek();\n    if (token.type !== type) return;\n    this.#peek = undefined; // Reset after consumed.\n    return token.value;\n  }\n\n  consume(type: TokenType): string {\n    const value = this.tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = this.peek();\n    throw new TypeError(\n      `Unexpected ${nextType} at ${index}, expected ${type}: ${DEBUG_URL}`,\n    );\n  }\n\n  text(): string {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = this.tryConsume(\"CHAR\") || this.tryConsume(\"ESCAPED\"))) {\n      result += value;\n    }\n    return result;\n  }\n}\n\n/**\n * Plain text.\n */\nexport interface Text {\n  type: \"text\";\n  value: string;\n}\n\n/**\n * A parameter designed to match arbitrary text within a segment.\n */\nexport interface Parameter {\n  type: \"param\";\n  name: string;\n}\n\n/**\n * A wildcard parameter designed to match multiple segments.\n */\nexport interface Wildcard {\n  type: \"wildcard\";\n  name: string;\n}\n\n/**\n * A set of possible tokens to expand when matching.\n */\nexport interface Group {\n  type: \"group\";\n  tokens: Token[];\n}\n\n/**\n * A sequence of path match characters.\n */\nexport type Token = Text | Parameter | Wildcard | Group;\n\n/**\n * Tokenized path instance.\n */\nexport class TokenData {\n  constructor(public readonly tokens: Token[]) {}\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { encodePath = NOOP_VALUE } = options;\n  const it = new Iter(lexer(str));\n\n  function consume(endType: TokenType): Token[] {\n    const tokens: Token[] = [];\n\n    while (true) {\n      const path = it.text();\n      if (path) tokens.push({ type: \"text\", value: encodePath(path) });\n\n      const param = it.tryConsume(\"PARAM\");\n      if (param) {\n        tokens.push({\n          type: \"param\",\n          name: param,\n        });\n        continue;\n      }\n\n      const wildcard = it.tryConsume(\"WILDCARD\");\n      if (wildcard) {\n        tokens.push({\n          type: \"wildcard\",\n          name: wildcard,\n        });\n        continue;\n      }\n\n      const open = it.tryConsume(\"{\");\n      if (open) {\n        tokens.push({\n          type: \"group\",\n          tokens: consume(\"}\"),\n        });\n        continue;\n      }\n\n      it.consume(endType);\n      return tokens;\n    }\n  }\n\n  const tokens = consume(\"END\");\n  return new TokenData(tokens);\n}\n\n/**\n * Transform tokens into a path building function.\n */\nfunction $compile<P extends ParamData>(\n  data: TokenData,\n  options: CompileOptions,\n): PathFunction<P> {\n  const { encode = encodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n\n  return function path(data: P = {} as P) {\n    const [path, ...missing] = fn(data);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends ParamData = ParamData>(\n  path: Path,\n  options: CompileOptions & ParseOptions = {},\n) {\n  return $compile<P>(\n    path instanceof TokenData ? path : parse(path, options),\n    options,\n  );\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\nfunction tokensToFunction(\n  tokens: Token[],\n  delimiter: string,\n  encode: Encode | false,\n) {\n  const encoders = tokens.map((token) =>\n    tokenToFunction(token, delimiter, encode),\n  );\n\n  return (data: ParamData) => {\n    const result: string[] = [\"\"];\n\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n\n    return result;\n  };\n}\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  delimiter: string,\n  encode: Encode | false,\n): (data: ParamData) => string[] {\n  if (token.type === \"text\") return () => [token.value];\n\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n\n    return (data) => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n\n  if (token.type === \"wildcard\" && encode !== false) {\n    return (data) => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n\n      return [\n        value\n          .map((value, index) => {\n            if (typeof value !== \"string\") {\n              throw new TypeError(\n                `Expected \"${token.name}/${index}\" to be a string`,\n              );\n            }\n\n            return encodeValue(value);\n          })\n          .join(delimiter),\n      ];\n    };\n  }\n\n  return (data) => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n\n    return [encodeValue(value)];\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nfunction $match<P extends ParamData>(\n  data: TokenData[],\n  options: MatchOptions = {},\n): MatchFunction<P> {\n  const {\n    decode = decodeURIComponent,\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    trailing = true,\n  } = options;\n  const flags = toFlags(options);\n  const sources: string[] = [];\n  const keys: Array<Parameter | Wildcard> = [];\n\n  for (const { tokens } of data) {\n    for (const seq of flatten(tokens, 0, [])) {\n      const regexp = sequenceToRegExp(seq, delimiter, keys);\n      sources.push(regexp);\n    }\n  }\n\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n\n  const re = new RegExp(pattern, flags);\n\n  const decoders = keys.map((key) => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return (value: string) => value.split(delimiter).map(decode);\n  });\n\n  return Object.assign(\n    function match(input: string) {\n      const m = re.exec(input);\n      if (!m) return false;\n\n      const { 0: path } = m;\n      const params = Object.create(null);\n\n      for (let i = 1; i < m.length; i++) {\n        if (m[i] === undefined) continue;\n\n        const key = keys[i - 1];\n        const decoder = decoders[i - 1];\n        params[key.name] = decoder(m[i]);\n      }\n\n      return { path, params };\n    },\n    { re },\n  );\n}\n\nexport type Path = string | TokenData;\n\nexport function match<P extends ParamData>(\n  path: Path | Path[],\n  options: MatchOptions & ParseOptions = {},\n): MatchFunction<P> {\n  const paths = Array.isArray(path) ? path : [path];\n  const items = paths.map((path) =>\n    path instanceof TokenData ? path : parse(path, options),\n  );\n\n  return $match(items, options);\n}\n\n/**\n * Flattened token set.\n */\ntype Flattened = Text | Parameter | Wildcard;\n\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(\n  tokens: Token[],\n  index: number,\n  init: Flattened[],\n): Generator<Flattened[]> {\n  if (index === tokens.length) {\n    return yield init;\n  }\n\n  const token = tokens[index];\n\n  if (token.type === \"group\") {\n    const fork = init.slice();\n    for (const seq of flatten(token.tokens, 0, fork)) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n\n  yield* flatten(tokens, index + 1, init);\n}\n\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction sequenceToRegExp(\n  tokens: Flattened[],\n  delimiter: string,\n  keys: Array<Parameter | Wildcard>,\n): string {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n\n  for (let i = 0; i < tokens.length; i++) {\n    const token = tokens[i];\n\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack = token.value;\n      isSafeSegmentParam ||= token.value.includes(delimiter);\n      continue;\n    }\n\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new TypeError(`Missing text after \"${token.name}\": ${DEBUG_URL}`);\n      }\n\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `(.+)`;\n      }\n\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n\n  return result;\n}\n\nfunction negate(delimiter: string, backtrack: string) {\n  const values = [delimiter, backtrack].filter(Boolean);\n  const isSimple = values.every((value) => value.length === 1);\n  if (isSimple) return `[^${escape(values.join(\"\"))}]`;\n  return `(?:(?!${values.map(escape).join(\"|\")}).)`;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAuQAA,OAAA,CAAAC,KAAA,GAAAA,KAAA;AAsEAD,OAAA,CAAAE,OAAA,GAAAA,OAAA;AA4KAF,OAAA,CAAAG,KAAA,GAAAA,KAAA;AAzfA,MAAMC,iBAAiB,GAAG,GAAG;AAC7B,MAAMC,UAAU,GAAIC,KAAa,IAAKA,KAAK;AAC3C,MAAMC,QAAQ,GAAG,qBAAqB;AACtC,MAAMC,WAAW,GAAG,mCAAmC;AACvD,MAAMC,SAAS,GAAG,mCAAmC;AA+ErD,MAAMC,aAAa,GAA8B;EAC/C;EACA,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR;EACA,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE;CACN;AAED;;;AAGA,SAASC,MAAMA,CAACC,GAAW;EACzB,OAAOA,GAAG,CAACC,OAAO,CAAC,sBAAsB,EAAE,MAAM,CAAC;AACpD;AAEA;;;AAGA,SAASC,OAAOA,CAACC,OAAgC;EAC/C,OAAOA,OAAO,CAACC,SAAS,GAAG,GAAG,GAAG,IAAI;AACvC;AAEA;;;AAGA,UAAUC,KAAKA,CAACL,GAAW;EACzB,MAAMM,KAAK,GAAG,CAAC,GAAGN,GAAG,CAAC;EACtB,IAAIO,CAAC,GAAG,CAAC;EAET,SAASC,IAAIA,CAAA;IACX,IAAId,KAAK,GAAG,EAAE;IAEd,IAAIC,QAAQ,CAACc,IAAI,CAACH,KAAK,CAAC,EAAEC,CAAC,CAAC,CAAC,EAAE;MAC7Bb,KAAK,IAAIY,KAAK,CAACC,CAAC,CAAC;MACjB,OAAOX,WAAW,CAACa,IAAI,CAACH,KAAK,CAAC,EAAEC,CAAC,CAAC,CAAC,EAAE;QACnCb,KAAK,IAAIY,KAAK,CAACC,CAAC,CAAC;MACnB;IACF,CAAC,MAAM,IAAID,KAAK,CAACC,CAAC,CAAC,KAAK,GAAG,EAAE;MAC3B,IAAIG,GAAG,GAAGH,CAAC;MAEX,OAAOA,CAAC,GAAGD,KAAK,CAACK,MAAM,EAAE;QACvB,IAAIL,KAAK,CAAC,EAAEC,CAAC,CAAC,KAAK,GAAG,EAAE;UACtBA,CAAC,EAAE;UACHG,GAAG,GAAG,CAAC;UACP;QACF;QAEA,IAAIJ,KAAK,CAACC,CAAC,CAAC,KAAK,IAAI,EAAE;UACrBb,KAAK,IAAIY,KAAK,CAAC,EAAEC,CAAC,CAAC;QACrB,CAAC,MAAM;UACLb,KAAK,IAAIY,KAAK,CAACC,CAAC,CAAC;QACnB;MACF;MAEA,IAAIG,GAAG,EAAE;QACP,MAAM,IAAIE,SAAS,CAAC,yBAAyBF,GAAG,KAAKb,SAAS,EAAE,CAAC;MACnE;IACF;IAEA,IAAI,CAACH,KAAK,EAAE;MACV,MAAM,IAAIkB,SAAS,CAAC,6BAA6BL,CAAC,KAAKV,SAAS,EAAE,CAAC;IACrE;IAEA,OAAOH,KAAK;EACd;EAEA,OAAOa,CAAC,GAAGD,KAAK,CAACK,MAAM,EAAE;IACvB,MAAMjB,KAAK,GAAGY,KAAK,CAACC,CAAC,CAAC;IACtB,MAAMM,IAAI,GAAGf,aAAa,CAACJ,KAAK,CAAC;IAEjC,IAAImB,IAAI,EAAE;MACR,MAAM;QAAEA,IAAI;QAAEC,KAAK,EAAEP,CAAC,EAAE;QAAEb;MAAK,CAAE;IACnC,CAAC,MAAM,IAAIA,KAAK,KAAK,IAAI,EAAE;MACzB,MAAM;QAAEmB,IAAI,EAAE,SAAS;QAAEC,KAAK,EAAEP,CAAC,EAAE;QAAEb,KAAK,EAAEY,KAAK,CAACC,CAAC,EAAE;MAAC,CAAE;IAC1D,CAAC,MAAM,IAAIb,KAAK,KAAK,GAAG,EAAE;MACxB,MAAMA,KAAK,GAAGc,IAAI,EAAE;MACpB,MAAM;QAAEK,IAAI,EAAE,OAAO;QAAEC,KAAK,EAAEP,CAAC;QAAEb;MAAK,CAAE;IAC1C,CAAC,MAAM,IAAIA,KAAK,KAAK,GAAG,EAAE;MACxB,MAAMA,KAAK,GAAGc,IAAI,EAAE;MACpB,MAAM;QAAEK,IAAI,EAAE,UAAU;QAAEC,KAAK,EAAEP,CAAC;QAAEb;MAAK,CAAE;IAC7C,CAAC,MAAM;MACL,MAAM;QAAEmB,IAAI,EAAE,MAAM;QAAEC,KAAK,EAAEP,CAAC;QAAEb,KAAK,EAAEY,KAAK,CAACC,CAAC,EAAE;MAAC,CAAE;IACrD;EACF;EAEA,OAAO;IAAEM,IAAI,EAAE,KAAK;IAAEC,KAAK,EAAEP,CAAC;IAAEb,KAAK,EAAE;EAAE,CAAE;AAC7C;AAEA,MAAMqB,IAAI;EAGRC,YAAoBC,MAAqC;IAArC,KAAAA,MAAM,GAANA,MAAM;IAF1BC,UAAA,CAAAC,GAAA;EAE4D;EAE5DC,IAAIA,CAAA;IACF,IAAI,CAACC,sBAAA,KAAI,EAAAH,UAAA,MAAM,EAAE;MACf,MAAMI,IAAI,GAAG,IAAI,CAACL,MAAM,CAACK,IAAI,EAAE;MAC/BC,sBAAA,KAAI,EAAAL,UAAA,EAASI,IAAI,CAAC5B,KAAK;IACzB;IACA,OAAO2B,sBAAA,KAAI,EAAAH,UAAA,MAAM;EACnB;EAEAM,UAAUA,CAACX,IAAe;IACxB,MAAMY,KAAK,GAAG,IAAI,CAACL,IAAI,EAAE;IACzB,IAAIK,KAAK,CAACZ,IAAI,KAAKA,IAAI,EAAE;IACzBU,sBAAA,KAAI,EAAAL,UAAA,EAASQ,SAAS,OAAC,CAAC;IACxB,OAAOD,KAAK,CAAC/B,KAAK;EACpB;EAEAiC,OAAOA,CAACd,IAAe;IACrB,MAAMnB,KAAK,GAAG,IAAI,CAAC8B,UAAU,CAACX,IAAI,CAAC;IACnC,IAAInB,KAAK,KAAKgC,SAAS,EAAE,OAAOhC,KAAK;IACrC,MAAM;MAAEmB,IAAI,EAAEe,QAAQ;MAAEd;IAAK,CAAE,GAAG,IAAI,CAACM,IAAI,EAAE;IAC7C,MAAM,IAAIR,SAAS,CACjB,cAAcgB,QAAQ,OAAOd,KAAK,cAAcD,IAAI,KAAKhB,SAAS,EAAE,CACrE;EACH;EAEAgC,IAAIA,CAAA;IACF,IAAIC,MAAM,GAAG,EAAE;IACf,IAAIpC,KAAyB;IAC7B,OAAQA,KAAK,GAAG,IAAI,CAAC8B,UAAU,CAAC,MAAM,CAAC,IAAI,IAAI,CAACA,UAAU,CAAC,SAAS,CAAC,EAAG;MACtEM,MAAM,IAAIpC,KAAK;IACjB;IACA,OAAOoC,MAAM;EACf;;;AAwCF;;;AAGA,MAAaC,SAAS;EACpBf,YAA4BC,MAAe;IAAf,KAAAA,MAAM,GAANA,MAAM;EAAY;;AADhD7B,OAAA,CAAA2C,SAAA,GAAAA,SAAA;AAIA;;;AAGA,SAAgB1C,KAAKA,CAACW,GAAW,EAAEG,OAAA,GAAwB,EAAE;EAC3D,MAAM;IAAE6B,UAAU,GAAGvC;EAAU,CAAE,GAAGU,OAAO;EAC3C,MAAM8B,EAAE,GAAG,IAAIlB,IAAI,CAACV,KAAK,CAACL,GAAG,CAAC,CAAC;EAE/B,SAAS2B,OAAOA,CAACO,OAAkB;IACjC,MAAMjB,MAAM,GAAY,EAAE;IAE1B,OAAO,IAAI,EAAE;MACX,MAAMkB,IAAI,GAAGF,EAAE,CAACJ,IAAI,EAAE;MACtB,IAAIM,IAAI,EAAElB,MAAM,CAACmB,IAAI,CAAC;QAAEvB,IAAI,EAAE,MAAM;QAAEnB,KAAK,EAAEsC,UAAU,CAACG,IAAI;MAAC,CAAE,CAAC;MAEhE,MAAME,KAAK,GAAGJ,EAAE,CAACT,UAAU,CAAC,OAAO,CAAC;MACpC,IAAIa,KAAK,EAAE;QACTpB,MAAM,CAACmB,IAAI,CAAC;UACVvB,IAAI,EAAE,OAAO;UACbL,IAAI,EAAE6B;SACP,CAAC;QACF;MACF;MAEA,MAAMC,QAAQ,GAAGL,EAAE,CAACT,UAAU,CAAC,UAAU,CAAC;MAC1C,IAAIc,QAAQ,EAAE;QACZrB,MAAM,CAACmB,IAAI,CAAC;UACVvB,IAAI,EAAE,UAAU;UAChBL,IAAI,EAAE8B;SACP,CAAC;QACF;MACF;MAEA,MAAMC,IAAI,GAAGN,EAAE,CAACT,UAAU,CAAC,GAAG,CAAC;MAC/B,IAAIe,IAAI,EAAE;QACRtB,MAAM,CAACmB,IAAI,CAAC;UACVvB,IAAI,EAAE,OAAO;UACbI,MAAM,EAAEU,OAAO,CAAC,GAAG;SACpB,CAAC;QACF;MACF;MAEAM,EAAE,CAACN,OAAO,CAACO,OAAO,CAAC;MACnB,OAAOjB,MAAM;IACf;EACF;EAEA,MAAMA,MAAM,GAAGU,OAAO,CAAC,KAAK,CAAC;EAC7B,OAAO,IAAII,SAAS,CAACd,MAAM,CAAC;AAC9B;AAEA;;;AAGA,SAASuB,QAAQA,CACfC,IAAe,EACftC,OAAuB;EAEvB,MAAM;IAAEuC,MAAM,GAAGC,kBAAkB;IAAEC,SAAS,GAAGpD;EAAiB,CAAE,GAClEW,OAAO;EACT,MAAM0C,EAAE,GAAGC,gBAAgB,CAACL,IAAI,CAACxB,MAAM,EAAE2B,SAAS,EAAEF,MAAM,CAAC;EAE3D,OAAO,SAASP,IAAIA,CAACM,IAAA,GAAU,EAAO;IACpC,MAAM,CAACN,IAAI,EAAE,GAAGY,OAAO,CAAC,GAAGF,EAAE,CAACJ,IAAI,CAAC;IACnC,IAAIM,OAAO,CAACpC,MAAM,EAAE;MAClB,MAAM,IAAIC,SAAS,CAAC,uBAAuBmC,OAAO,CAACC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;IAClE;IACA,OAAOb,IAAI;EACb,CAAC;AACH;AAEA;;;AAGA,SAAgB7C,OAAOA,CACrB6C,IAAU,EACVhC,OAAA,GAAyC,EAAE;EAE3C,OAAOqC,QAAQ,CACbL,IAAI,YAAYJ,SAAS,GAAGI,IAAI,GAAG9C,KAAK,CAAC8C,IAAI,EAAEhC,OAAO,CAAC,EACvDA,OAAO,CACR;AACH;AAKA,SAAS2C,gBAAgBA,CACvB7B,MAAe,EACf2B,SAAiB,EACjBF,MAAsB;EAEtB,MAAMO,QAAQ,GAAGhC,MAAM,CAACiC,GAAG,CAAEzB,KAAK,IAChC0B,eAAe,CAAC1B,KAAK,EAAEmB,SAAS,EAAEF,MAAM,CAAC,CAC1C;EAED,OAAQD,IAAe,IAAI;IACzB,MAAMX,MAAM,GAAa,CAAC,EAAE,CAAC;IAE7B,KAAK,MAAMsB,OAAO,IAAIH,QAAQ,EAAE;MAC9B,MAAM,CAACvD,KAAK,EAAE,GAAG2D,MAAM,CAAC,GAAGD,OAAO,CAACX,IAAI,CAAC;MACxCX,MAAM,CAAC,CAAC,CAAC,IAAIpC,KAAK;MAClBoC,MAAM,CAACM,IAAI,CAAC,GAAGiB,MAAM,CAAC;IACxB;IAEA,OAAOvB,MAAM;EACf,CAAC;AACH;AAEA;;;AAGA,SAASqB,eAAeA,CACtB1B,KAAY,EACZmB,SAAiB,EACjBF,MAAsB;EAEtB,IAAIjB,KAAK,CAACZ,IAAI,KAAK,MAAM,EAAE,OAAO,MAAM,CAACY,KAAK,CAAC/B,KAAK,CAAC;EAErD,IAAI+B,KAAK,CAACZ,IAAI,KAAK,OAAO,EAAE;IAC1B,MAAMgC,EAAE,GAAGC,gBAAgB,CAACrB,KAAK,CAACR,MAAM,EAAE2B,SAAS,EAAEF,MAAM,CAAC;IAE5D,OAAQD,IAAI,IAAI;MACd,MAAM,CAAC/C,KAAK,EAAE,GAAGqD,OAAO,CAAC,GAAGF,EAAE,CAACJ,IAAI,CAAC;MACpC,IAAI,CAACM,OAAO,CAACpC,MAAM,EAAE,OAAO,CAACjB,KAAK,CAAC;MACnC,OAAO,CAAC,EAAE,CAAC;IACb,CAAC;EACH;EAEA,MAAM4D,WAAW,GAAGZ,MAAM,IAAIjD,UAAU;EAExC,IAAIgC,KAAK,CAACZ,IAAI,KAAK,UAAU,IAAI6B,MAAM,KAAK,KAAK,EAAE;IACjD,OAAQD,IAAI,IAAI;MACd,MAAM/C,KAAK,GAAG+C,IAAI,CAAChB,KAAK,CAACjB,IAAI,CAAC;MAC9B,IAAId,KAAK,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,EAAE+B,KAAK,CAACjB,IAAI,CAAC;MAE1C,IAAI,CAAC+C,KAAK,CAACC,OAAO,CAAC9D,KAAK,CAAC,IAAIA,KAAK,CAACiB,MAAM,KAAK,CAAC,EAAE;QAC/C,MAAM,IAAIC,SAAS,CAAC,aAAaa,KAAK,CAACjB,IAAI,2BAA2B,CAAC;MACzE;MAEA,OAAO,CACLd,KAAK,CACFwD,GAAG,CAAC,CAACxD,KAAK,EAAEoB,KAAK,KAAI;QACpB,IAAI,OAAOpB,KAAK,KAAK,QAAQ,EAAE;UAC7B,MAAM,IAAIkB,SAAS,CACjB,aAAaa,KAAK,CAACjB,IAAI,IAAIM,KAAK,kBAAkB,CACnD;QACH;QAEA,OAAOwC,WAAW,CAAC5D,KAAK,CAAC;MAC3B,CAAC,CAAC,CACDsD,IAAI,CAACJ,SAAS,CAAC,CACnB;IACH,CAAC;EACH;EAEA,OAAQH,IAAI,IAAI;IACd,MAAM/C,KAAK,GAAG+C,IAAI,CAAChB,KAAK,CAACjB,IAAI,CAAC;IAC9B,IAAId,KAAK,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,EAAE+B,KAAK,CAACjB,IAAI,CAAC;IAE1C,IAAI,OAAOd,KAAK,KAAK,QAAQ,EAAE;MAC7B,MAAM,IAAIkB,SAAS,CAAC,aAAaa,KAAK,CAACjB,IAAI,kBAAkB,CAAC;IAChE;IAEA,OAAO,CAAC8C,WAAW,CAAC5D,KAAK,CAAC,CAAC;EAC7B,CAAC;AACH;AAoBA;;;AAGA,SAAS+D,MAAMA,CACbhB,IAAiB,EACjBtC,OAAA,GAAwB,EAAE;EAE1B,MAAM;IACJuD,MAAM,GAAGC,kBAAkB;IAC3Bf,SAAS,GAAGpD,iBAAiB;IAC7BoE,GAAG,GAAG,IAAI;IACVC,QAAQ,GAAG;EAAI,CAChB,GAAG1D,OAAO;EACX,MAAM2D,KAAK,GAAG5D,OAAO,CAACC,OAAO,CAAC;EAC9B,MAAM4D,OAAO,GAAa,EAAE;EAC5B,MAAMC,IAAI,GAAgC,EAAE;EAE5C,KAAK,MAAM;IAAE/C;EAAM,CAAE,IAAIwB,IAAI,EAAE;IAC7B,KAAK,MAAMwB,GAAG,IAAIC,OAAO,CAACjD,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE;MACxC,MAAMkD,MAAM,GAAGC,gBAAgB,CAACH,GAAG,EAAErB,SAAS,EAAEoB,IAAI,CAAC;MACrDD,OAAO,CAAC3B,IAAI,CAAC+B,MAAM,CAAC;IACtB;EACF;EAEA,IAAIE,OAAO,GAAG,OAAON,OAAO,CAACf,IAAI,CAAC,GAAG,CAAC,GAAG;EACzC,IAAIa,QAAQ,EAAEQ,OAAO,IAAI,MAAMtE,MAAM,CAAC6C,SAAS,CAAC,KAAK;EACrDyB,OAAO,IAAIT,GAAG,GAAG,GAAG,GAAG,MAAM7D,MAAM,CAAC6C,SAAS,CAAC,KAAK;EAEnD,MAAM0B,EAAE,GAAG,IAAIC,MAAM,CAACF,OAAO,EAAEP,KAAK,CAAC;EAErC,MAAMU,QAAQ,GAAGR,IAAI,CAACd,GAAG,CAAEuB,GAAG,IAAI;IAChC,IAAIf,MAAM,KAAK,KAAK,EAAE,OAAOjE,UAAU;IACvC,IAAIgF,GAAG,CAAC5D,IAAI,KAAK,OAAO,EAAE,OAAO6C,MAAM;IACvC,OAAQhE,KAAa,IAAKA,KAAK,CAACgF,KAAK,CAAC9B,SAAS,CAAC,CAACM,GAAG,CAACQ,MAAM,CAAC;EAC9D,CAAC,CAAC;EAEF,OAAOiB,MAAM,CAACC,MAAM,CAClB,SAASrF,KAAKA,CAACsF,KAAa;IAC1B,MAAMC,CAAC,GAAGR,EAAE,CAACS,IAAI,CAACF,KAAK,CAAC;IACxB,IAAI,CAACC,CAAC,EAAE,OAAO,KAAK;IAEpB,MAAM;MAAE,CAAC,EAAE3C;IAAI,CAAE,GAAG2C,CAAC;IACrB,MAAME,MAAM,GAAGL,MAAM,CAACM,MAAM,CAAC,IAAI,CAAC;IAElC,KAAK,IAAI1E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGuE,CAAC,CAACnE,MAAM,EAAEJ,CAAC,EAAE,EAAE;MACjC,IAAIuE,CAAC,CAACvE,CAAC,CAAC,KAAKmB,SAAS,EAAE;MAExB,MAAM+C,GAAG,GAAGT,IAAI,CAACzD,CAAC,GAAG,CAAC,CAAC;MACvB,MAAM2E,OAAO,GAAGV,QAAQ,CAACjE,CAAC,GAAG,CAAC,CAAC;MAC/ByE,MAAM,CAACP,GAAG,CAACjE,IAAI,CAAC,GAAG0E,OAAO,CAACJ,CAAC,CAACvE,CAAC,CAAC,CAAC;IAClC;IAEA,OAAO;MAAE4B,IAAI;MAAE6C;IAAM,CAAE;EACzB,CAAC,EACD;IAAEV;EAAE,CAAE,CACP;AACH;AAIA,SAAgB/E,KAAKA,CACnB4C,IAAmB,EACnBhC,OAAA,GAAuC,EAAE;EAEzC,MAAMgF,KAAK,GAAG5B,KAAK,CAACC,OAAO,CAACrB,IAAI,CAAC,GAAGA,IAAI,GAAG,CAACA,IAAI,CAAC;EACjD,MAAMiD,KAAK,GAAGD,KAAK,CAACjC,GAAG,CAAEf,IAAI,IAC3BA,IAAI,YAAYJ,SAAS,GAAGI,IAAI,GAAG9C,KAAK,CAAC8C,IAAI,EAAEhC,OAAO,CAAC,CACxD;EAED,OAAOsD,MAAM,CAAC2B,KAAK,EAAEjF,OAAO,CAAC;AAC/B;AAOA;;;AAGA,UAAU+D,OAAOA,CACfjD,MAAe,EACfH,KAAa,EACbuE,IAAiB;EAEjB,IAAIvE,KAAK,KAAKG,MAAM,CAACN,MAAM,EAAE;IAC3B,OAAO,MAAM0E,IAAI;EACnB;EAEA,MAAM5D,KAAK,GAAGR,MAAM,CAACH,KAAK,CAAC;EAE3B,IAAIW,KAAK,CAACZ,IAAI,KAAK,OAAO,EAAE;IAC1B,MAAMyE,IAAI,GAAGD,IAAI,CAACE,KAAK,EAAE;IACzB,KAAK,MAAMtB,GAAG,IAAIC,OAAO,CAACzC,KAAK,CAACR,MAAM,EAAE,CAAC,EAAEqE,IAAI,CAAC,EAAE;MAChD,OAAOpB,OAAO,CAACjD,MAAM,EAAEH,KAAK,GAAG,CAAC,EAAEmD,GAAG,CAAC;IACxC;EACF,CAAC,MAAM;IACLoB,IAAI,CAACjD,IAAI,CAACX,KAAK,CAAC;EAClB;EAEA,OAAOyC,OAAO,CAACjD,MAAM,EAAEH,KAAK,GAAG,CAAC,EAAEuE,IAAI,CAAC;AACzC;AAEA;;;AAGA,SAASjB,gBAAgBA,CACvBnD,MAAmB,EACnB2B,SAAiB,EACjBoB,IAAiC;EAEjC,IAAIlC,MAAM,GAAG,EAAE;EACf,IAAI0D,SAAS,GAAG,EAAE;EAClB,IAAIC,kBAAkB,GAAG,IAAI;EAE7B,KAAK,IAAIlF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGU,MAAM,CAACN,MAAM,EAAEJ,CAAC,EAAE,EAAE;IACtC,MAAMkB,KAAK,GAAGR,MAAM,CAACV,CAAC,CAAC;IAEvB,IAAIkB,KAAK,CAACZ,IAAI,KAAK,MAAM,EAAE;MACzBiB,MAAM,IAAI/B,MAAM,CAAC0B,KAAK,CAAC/B,KAAK,CAAC;MAC7B8F,SAAS,GAAG/D,KAAK,CAAC/B,KAAK;MACvB+F,kBAAkB,KAAlBA,kBAAkB,GAAKhE,KAAK,CAAC/B,KAAK,CAACgG,QAAQ,CAAC9C,SAAS,CAAC;MACtD;IACF;IAEA,IAAInB,KAAK,CAACZ,IAAI,KAAK,OAAO,IAAIY,KAAK,CAACZ,IAAI,KAAK,UAAU,EAAE;MACvD,IAAI,CAAC4E,kBAAkB,IAAI,CAACD,SAAS,EAAE;QACrC,MAAM,IAAI5E,SAAS,CAAC,uBAAuBa,KAAK,CAACjB,IAAI,MAAMX,SAAS,EAAE,CAAC;MACzE;MAEA,IAAI4B,KAAK,CAACZ,IAAI,KAAK,OAAO,EAAE;QAC1BiB,MAAM,IAAI,IAAI6D,MAAM,CAAC/C,SAAS,EAAE6C,kBAAkB,GAAG,EAAE,GAAGD,SAAS,CAAC,IAAI;MAC1E,CAAC,MAAM;QACL1D,MAAM,IAAI,MAAM;MAClB;MAEAkC,IAAI,CAAC5B,IAAI,CAACX,KAAK,CAAC;MAChB+D,SAAS,GAAG,EAAE;MACdC,kBAAkB,GAAG,KAAK;MAC1B;IACF;EACF;EAEA,OAAO3D,MAAM;AACf;AAEA,SAAS6D,MAAMA,CAAC/C,SAAiB,EAAE4C,SAAiB;EAClD,MAAMI,MAAM,GAAG,CAAChD,SAAS,EAAE4C,SAAS,CAAC,CAACK,MAAM,CAACC,OAAO,CAAC;EACrD,MAAMC,QAAQ,GAAGH,MAAM,CAACI,KAAK,CAAEtG,KAAK,IAAKA,KAAK,CAACiB,MAAM,KAAK,CAAC,CAAC;EAC5D,IAAIoF,QAAQ,EAAE,OAAO,KAAKhG,MAAM,CAAC6F,MAAM,CAAC5C,IAAI,CAAC,EAAE,CAAC,CAAC,GAAG;EACpD,OAAO,SAAS4C,MAAM,CAAC1C,GAAG,CAACnD,MAAM,CAAC,CAACiD,IAAI,CAAC,GAAG,CAAC,KAAK;AACnD","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}